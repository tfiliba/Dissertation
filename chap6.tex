\chapter{Analysis} \label{chap:Analysis}

%TODO: edit this awkwardness
The ORCAS tool is analyzed by looking at three case studies. 
We created three instrument types: Spectrometer, High Resolution Spectrometer, and FX Correlator, as defined in Sections \ref{Real Time Radio Astronomy Algorithms:Spectroscopy}, \ref{Real Time Radio Astronomy Algorithms:Pulsar Processing}, and \ref{Real Time Radio Astronomy Algorithms:Correlation}. 
Each case study was chosen to illustrate a different aspect of the toolflow.
The spectrometer gives an example of the end to end toolflow using a simple dataflow, the high resolution spectrometer allows us to explore tradeoffs in the design space and the FX correlator shows how the tool behaves when designing very large instruments.


%Simple spectrometer placement

%TODO: Include appropriate FFT or PFB benchmarks

%Summary: describe how we get real numbers to put into previous part
%Goal: define and obtain real numbers from the previous part
%\section{Benchmarks}

%\subsection{Cost}

%Summary: case studies describing partitioning of realistic-scale instruments
%Goal: show successful application of tool to design of realistic instruments
%provide analysis comparing this to hand-designed instruments 
\section{Spectrometer Case Study}
The spectrometer is a simple instrument, making it easy to follow the end to end toolflow.
We design %a 50 MHz and 
an 800 MHz spectrometer that breaks the band into 1024 channels.
%TODO: what is a reasonable integration time here


\subsection{Spectrometer Definition}
Defining a simple spectrometer requires very few parameters. 
First, as with most instruments, the astronomer must specify the sky bandwidth the instrument must process, defined in MHz and the number of bits in each ADC sample.
Then, the desired spectral resolution is defined in MHz per channel, or analogously, the number of channels that should be used to break up the bandwidth.
Finally, the integration time needs to be defined.

One optional parameter, number of antennas, can also be defined. 
This describes the number of independent spectrometers that need to be created.
While this parameter does not affect the end to end processing for each antenna, knowing how many spectrometers are needed allows for more efficient use of the hardware.

The 800 MHz spectrometer is created simply by defining the parameters and instantiating a Spectrometer object as follows:

\lstinputlisting[language=Python,
    %caption=My Class,
    label={spec_defn.py},
    breaklines=true,
  ]{code/C6/spec_defn.py}

\subsection{Spectrometer Dataflow}

%TODO: add detection step
\begin{figure}[ht!]
  \centering
    \includegraphics[width=1\textwidth]{Images/C4/spectrometer_dataflow.pdf}
  \caption{General Spectrometer Dataflow Model}
  \label{fig: C4/spectrometer_dataflow.pdf}
\end{figure}

The spectrometer instrument definition generates a very simple dataflow. 
Figure \ref{fig: C4/spectrometer_dataflow.pdf} shows the general dataflow model for a single antenna spectrometer. 
This model can be applied to any spectrometer, as the spectrometer parameters do not affect how many computational blocks are required or the interconnect layout. 
The ADC feeds data into an FIR filter. 
Then the filtered signal is transformed into channels in the FFT and the complex samples from the FFT are converted to power data by the detect block.
Finally, the data from each channel is accumulated and saved to disk. Regardless of the parameters the astronomer chooses, the dataflow will be the same. 

The parameters for each block come directly from the instrument definition. 
The FIR parameters come from the number of FIR taps and window shape, the FFT is simply defined by the FFT length parameter and the accumulator also is parameterized by the FFT length as well as the integration time. 
In this model and the follow case studies the detect stage and accumulator are combined into a single block because they both require very few resources.
The code below shows how the blocks are added to the dataflow model.

\lstinputlisting[language=Python,
    %caption=My Class,
    label={spec_dflow.py},
    breaklines=true,
  ]{code/C6/spec_dflow.py}

\subsection{Spectrometer Mapping}
As a simple case study, an 1024 channel 800 MHz spectrometer is mapped using the ROACH and GTX 580-based NRAO server as potential platforms. 
ORCAS produces a solution that maps the entire design to a single ROACH board.
This solution is obviously correct since the bandwidth cannot be processed by a single GPU and a single ROACH is cheaper than a combination of boards.
The mapping produced by ORCAS is shown below.

\lstinputlisting[
    %caption=My Class,
    label={spec_800_result.txt},
    breaklines=true,
  ]{code/C6/spec_800_result.txt}
  

%\lstinputlisting[
%    %caption=My Class,
%    label={spec_dflow.py},
%    breaklines=true,
%  ]{code/C6/spec_050_result.txt}
  
%\subsection{Cost}
%\subsection{Power}

\section{High Resolution Spectrometer Case Study}
The high resolution spectrometer is a useful instrument for SETI. 
The two stage channelization creates a large number of channels without using an FFT that is too large to fit on a single board.


\subsection{High Resolution Spectrometer Definition}
The main difference between a spectrometer and a high resolution spectrometer is the need for two stages of channelization rather than just one. 
The sky bandwidth, integration time, and number of antennas are defined in the same way as the previous spectrometer type. 

The spectral resolution is defined differently, because both the coarse and fine resolutions need to be defined. 
The coarse resolution defines how many channels the whole sky bandwidth should be broken up into initially.
The fine resolution defines how many channels each coarse channel is broken into.
Both can be described in MHz per channel.

\subsection{High Resolution Spectrometer Dataflow}

%TODO: add detection step
\begin{figure}[ht!]
  \centering
    \includegraphics[width=1\textwidth]{Images/C4/hires_spectrometer_dataflow.pdf}
  \caption[Example High Resolution Spectrometer Dataflow Model]{Example High Resolution Spectrometer Dataflow Model
%  \textit{
%  This figure shows an example dataflow for a high resolution spectrometer with 4 coarse FFT channels.
%  Like the previous spectrometer, the data comes in through an ADC, is filtered and then channelized using a coarse FFT.
%  Then, to achieve a higher resolution, each coarse channel is divided into sub-channels using the 4 fine FFT blocks in the dataflow. 
%  }
  }

  \label{fig: C4/hires_spectrometer_dataflow.pdf}
\end{figure}

The high resolution spectrometer dataflow does depend on the parameters specified in the instrument description. 
An example dataflow is shown in Figure \ref{fig: C4/hires_spectrometer_dataflow.pdf}. 
The first three blocks in the dataflow are exactly the same as the spectrometer dataflow described in the previous section. 
An ADC feeds data into an FIR filter followed by an FFT and reorders the data in the corner turn block, grouping data from the same channel together. 
After the corner turn, the algorithm is modified to accommodate the higher resolution required. 
The first FFT divides the band into a number of coarse channels and then each coarse channel must be further divided into a number of fine channels. 
The coarse FFT must feed its data to a separate fine FFT for each coarse channel, so the number of fine FFTs in the dataflow diagram will vary based on the number of coarse channels.
At this point, each coarse channel is processed in an independent pipeline which the finely channelizes the data, calculates the power of the finely channelized data in the detect block, and accumulates and records the data to disk. 
The example in Figure \ref{fig: C4/hires_spectrometer_dataflow.pdf} shows a spectrometer that divides the data into 4 coarse channels.

%\subsection{Cost}
%\subsection{Power}

\subsection{Algorithmic Exploration}

The Arecibo L-band feed array, pictured in Figure \ref{fig: C3/alfa_feed.png} has 7 dual-polarization beams. 
The SERENDIP V.v instrument was only able to process one beam at a time, but its planned successor, SERENDIP 6, will process 300MHz from each beam-pol.

\begin{figure}[ht!]
  \centering
    \includegraphics[width=\textwidth]{Images/C3/alfa_feed.png}
  \caption{Arecibo ALFA Feed}
  \label{fig: C3/alfa_feed.png}
\end{figure}

In this case study, we analyze the design space for a 300 MHz 256 million channel spectrometer, similar to the SERENDIP 6 instrument.
This instrument provides an interesting case study because the number of channels is so large.
The number of channels in the coarse and fine FFTs can be varied, as long as the product remains 256 million.
We explore this design space by varying the dimensions and number of antennas to see how the channel balance affects the final cost of the instrument.

This instrument is designed using ROACH boards and the GTX 580-based NRAO server as supported platforms, and uses the FIR and FFT benchmarks presented in Chapter \ref{chap:Algorithm Partitioning}.
To aid the linear program, we assume reordering the coarse FFT data is infeasible on the GPU and force the design to reorder the data on the FPGA.


\begin{sidewaystable}
\input{Tables/wbspec_table_old.tex}
\caption{134 Million Channel High Resolution Spectrometer Design Space}
\label{tab: C5/highres_spec_design_space}
\end{sidewaystable} 

%\begin{sidewaystable}
%\input{Tables/wbspec_table.tex}
%\end{sidewaystable} 

Table \ref{tab: C5/highres_spec_design_space} shows the results of this design space exploration. 
The optimal configurations for each row are highlighted in purple.
We observe that extreme values for the number of channels tend to increase costs, likely because it's difficult to put larger blocks together on the same board and get high utilization of the hardware.
Each test was run with a 30 minute time limit on my personal laptop, a 2011 Macbook Air, to ensure that the designs could converge quickly.
One test, the 7 antenna 512 by 262,144 channel spectrometer did not converge within the specified time.
While it might be able to converge given more time, the resulting table makes it clear that the optimal configuration is unlikely to lie in that square, and there is no need to spend extra time trying to get a solution.

%results for hi res spectrometer (gbt and seti)

%Serendip 6 300MHz 7 ant 2 pol

%1Hz resolution (256 million channels)

%Greenbank 2.5GHz 1 beam 2 pols

%1 Hz resolution

%Same benchmarks as before, just discuss large bw, multi stage fft



\section{FX Correlator Case Study}
\subsection{FX Correlator Definition}
An FX Correlator is also defined by the amount of bandwidth it processes, number of channels, and integration time, but now the number of antennas is a necessary parameter.

\subsection{FX Correlator Dataflow}

The FX dataflow model is based on the algorithm used by the CASPER correlator described in Section \ref{Related Work:Radio Astronomy}. The processing model is described by replicating two basic pipelines, called an F-Engine and an X-Engine. The number of times each pipeline needs to be replicated depends on the number of antennas and number of channels this correlator requires.

\begin{figure}[h!]
  \centering
    \includegraphics[width=0.55\textwidth]{Images/C4/fx_f_engine.pdf}
  \caption{FX Correlator F-Engine Model}
  \label{fig: C4/fx_f_engine.pdf}
\end{figure}

An F-Engine, pictured in Figure \ref{fig: C4/fx_f_engine.pdf} is responsible for channelizing the data from a single antenna. 
%TODO: explain or reference PFB (should be explained in C2 or 3?)
It takes in data from an ADC, and channelizes the data using an FIR and FFT to create a polyphase filter bank, or PFB. 
Then the data from the PFB is rearranged by the corner turn block, by grouping together data from the same channels.
The number of F-Engines in the correlator dataflow will vary with the number of antennas.

%TODO: add detection step
\begin{figure}[h!]
  \centering
    \includegraphics[width=0.55\textwidth]{Images/C4/fx_x_engine.pdf}
  \caption{FX Correlator X-Engine Model}
  \label{fig: C4/fx_x_engine.pdf}
\end{figure}

The second pipeline, the X-Engine, processes the channelized data. 
Each X-Engine takes a single channel of data from every antenna in the array, cross-correlates the data, calculates the power of the baselines in the detect stage, accumulates each baseline and stores the accumulated data to disk. 
Figure \ref{fig: C4/fx_x_engine.pdf} shows the pipeline for a single X-Engine. 
Since each X-Engine only operates on a single channel, the total number of X-Engines in the correlator must be the same as the number of channels in the FFT.


%TODO: add detection step
\begin{figure}[h!]
  \centering
    \includegraphics[width=1\textwidth]{Images/C4/fx_dataflow.pdf}
  \caption{Example FX Correlator Dataflow Model}
  \label{fig: C6/fx_dataflow.pdf}
\end{figure}

The dataflow for an FX correlator will vary quite a bit based on the input parameters. 
Figure \ref{fig: C6/fx_dataflow.pdf} shows an example three antenna four channel FX correlator. 
The left half of the figure has three F-engines, one for each of the three antennas.
The right half has four X-Engines, one for each channel.
In the center, since each X-Engine requires data from every F-engine, the cross-correlation blocks, represented by an \emph{X} and the Corner Turn blocks are connected in an all-to-all configuration.

\subsection{FX Correlator Mapping}
The FX Correlator is evaluated by investigating how correlator design scales from 16 to 512 dual polarization antennas.
Note that a 512 dual polarization antenna has 1024 inputs because each antenna produces 2 streams of data.
The design is based on the planned HERA Correlator that processes 100 MHz of data and divides it into 1024 channels.

I use the technique of block combining described in Section \ref{Algorithm Partitioning:Optimization} in two ways to ensure the problem can be solved quickly even when the number of antennas is large.
We expect the FIR and FFT will be placed together so these blocks are combined into a single block called a PFB.
Then, since we expect to see multiple PFBs on the same board, every group of four PFBs is combined into a single block that requires four times the resources of a single PFB.
The X-Engines are combined in the same way, since processing a single channel takes very few resources.

The symmetry of the correlator dataflow makes this a good instrument to observe the effects of the ILP options, single design and single implementation.
Just by looking at the results for the 16 antenna mapping with both options disabled, it is already apparent that the ILP is putting small blocks anywhere it can fit them, without much regard for the existing symmetry.
In the results below we see that the XEng blocks have been allocated asymmetrically.

\lstinputlisting[
    %caption=My Class,
    label={corr_si0_sd0_16_result.txt},
    breaklines=true,
  ]{code/C6/corr_si0_sd0_16_result.txt}
  
In this case, enabling both options doesn't alter the cost but for larger correlators making the design symmetric will require additional ROACH boards.
One observed side effect of this approach is the fact that the design might end up creating more blocks than the design originally required.
Consider the case where seven `A' blocks need to be distributed among four boards. 
If the single design option is off, the ILP can allocate those blocks however it wants.
But enabling the single design option makes it impossible to allocate them across those four boards and would come up with a solution that requires seven boards.
This is clearly inefficient and is solved by relaxing the constraint on the total number of blocks.
Rather than requiring the total number of implemented `A' blocks to sum to the total number of required blocks, the constraint requires that the number of implemented `A' blocks is greater than or equal to the number of required blocks.
In the example, it would allow the instantiated design to add another `A' block and just put two blocks on each board.
Relaxing this constraint can also inadvertently create extra blocks that aren't needed.
The mapping fo the 16 antenna placement with both options enabled, listed below, overspecifes the number of XEng blocks to make all the GPU designs the same.
  
  \lstinputlisting[
    %caption=My Class,
    label={corr_si1_sd1_16_result.txt},
    breaklines=true,
  ]{code/C6/corr_si1_sd1_16_result.txt}
  
%Analyzing the larger design space, we see this trend continue. 
Table \ref{tab: C6/fx_corr_si0_sd0.tex} and Table \ref{tab: C6/fx_corr_si1_sd1.tex} show the entire design space optimized for dollars.
%The tests with the options disabled consistently use fewer boards, resulting in a lower cost design.
The tests with both options enabled consistently require at least as many boards as the placement that did not preserve symmetry.
In both cases, we see a quadratic scaling in the number of GPU servers required and a linear scaling in the number of ROACH boards indicating that the cross correlation step should be implemented on GPUs and the channelization should be on FPGAs.

We also note that enabling these options increases the execution time of the ILP.
The execution time benchmarks were run on a server with two Quad-Core AMD Opteron 2376 Processors and 16GB of RAM.
The increase in runtime when enabling either or both options is expected since these options directly affect the ILP structure by adding a number of constraints.



\begin{table}
\centering
\input{Tables/fx_corr_si0_sd0.tex}
\caption{FX Correlator Design Space using ROACH boards and GTX 680 servers with Single Implementation and Single Design options disabled optimized for dollars}
\label{tab: C6/fx_corr_si0_sd0.tex}

\input{Tables/fx_corr_si1_sd1.tex}
\caption{FX Correlator Design Space using ROACH boards and GTX 680 servers with Single Implementation and Single Design options enabled optimized for dollars}
\label{tab: C6/fx_corr_si1_sd1.tex}
\end{table} 

Since HERA is a planned instrument it is also interesting to see how this design will map onto newer technology and compare that to the planned design.
To do this, I analyze the same design but I use the ROACH 2 board and a server that contains two GTX 690s costing \$5,500 as target platforms.
Rather than get new benchmarks for the GTX 690 and a ROACH 2, I use existing benchmarks to estimate the performance of these blocks on the new architecture.
The FPGA benchmarks are obtained by assuming the number of resources required will be the same on the ROACH 1 and the ROACH 2.
These resource benchmarks are divided by the amount of available resources on the ROACH 2 to get the percent utilization for each resource.
The GTX 690 board has two Keplar GPUs while the GTX 680 only has one, so, for the server, we assume the performance of a server with two GTX 690 boards is four times the performance of a server with a single GTX 680.
CASPER Memo 48 \cite{Schollar:2012vwa} has performance data for the cross correlation block on a GTX 680, so the utilization is reduced by a factor of four to estimate the cross correlation performance on the target server.
The FIR and FFT performance is estimated by using the resource utilization for the GTX 580 and reducing it by a factor of four.
This provides a reasonable estimate, since the GTX 680 may provide a performance increase over the GTX 580, but we don't expect a significant increase without reoptimizing the code.

Figure \ref{tab: C6/fx_corr_si1_sd1_nextgen.tex} shows the performance data for the same design on the newer platforms with single design and single implementation enabled
The smaller correlators don't see a significant price benefit from the added resources, likely because of bandwidth limitations, but the larger correlators are able to take advantage of the additional resources and the 512 antenna correlator gets a cost reduction of over 50\% simply by switching to the next generation technology.

\begin{table}
\input{Tables/fx_corr_si1_sd1_nextgen.tex}
\caption{FX Correlator Design Space using ROACH 2 boards and Dual GTX 690 servers  with Single Implementation and Single Design options enabled optimized for dollars}
\label{tab: C6/fx_corr_si1_sd1_nextgen.tex}
\end{table} 

